{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОЦЕНКА РЕЛЕВАНТНОСТИ ТЕСТИРОВАНИЯ И РАНЖИРОВАНИЯ МОДЕЛЕЙ В ЗАВИСИМОСТИ ОТ ОБЪЕМА ДАТАСЕТА\n",
    "\n",
    "Методы машинного обучения все чаще используются в различных областях жизнедеятельности. Ежегодно множество научных коллективов разрабатывают новые распознающие модели, соревнуясь при этом в показателях качества на открытых датасетах. В некоторых задачах показатели точности давно превысили 99\\%, при этом лучшие в таблице ранжирования модели зачастую отличаются между собой на сотые доли процентов. Принимая в расчет объемы датасетов, резонным становится вопрос о релевантности оценки качества и достоверности ранжирования различных распознающих моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Математическая модель\n",
    "\n",
    "Итак, мы говорим, что бенчмарк задает задачу, под этим мы понимаем, что существует вероятностное пространство $( \\Omega ,\\mathcal{F} ,P)$, множество объектов, предполагаемое бенчмарком, с сигма-алгеброй $(O,\\mathcal{F}_{O})$ и счетное число  измеримых и независимых в совокупности отображений $\\xi _{i} :\\Omega \\rightarrow O$ с совпадающими распределениями. Тестовая часть датасета $O_t$ это конечное множество независимых реализаций случайных элементов $\\xi _{i}$. На элементах множества $O$ задано измеримое отображение $v$ в пространство возможных ответов на объекте $K$, которое представляет собой сопоставление объектам правильных ответов. Модель $m$ также является измеримым отображением из  $O$ в $K$, введем функцию $g_{m} :O\\rightarrow \\{0,1\\}$, \n",
    "\\begin{equation}\n",
    "    g_{m}( x) =I[ m( x) =v( x)],\n",
    "\\end{equation}\n",
    "где $I[\\cdot]$--функция индикатор, принимающая 1, если выражение верно и 0 иначе. Тогда Accuracy $A^{t}_{m}$ модели $m$ на $O_t$ вычисляется как\n",
    "\\begin{equation}\n",
    "    A_{m}^{t} =\\sum _{x\\in O_{t}} g_{m}( x) /\\left| O_{t}\\right|,\n",
    "\\end{equation}\n",
    "где $\\left| O_{t}\\right|$ объем тестовой выборки. Легко заметить, что $g_m$ измерима. Исходя из вышесказанного, естественно дать определение Accuracy $A_m$ модели $m$ в задаче как\n",
    "\\begin{equation}\n",
    "    A_{m} =E_{P}[ g_{m}( \\xi _{0})].\n",
    "\\end{equation}\n",
    "Далее мы будем предполагать, что случайные величины $\\{g_{m}( \\xi _{i})\\}$ для всех рассматриваемых моделей независимы в совокупности.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Принадлежность модели к высококачественным или низкокачественным\n",
    "Итак, пусть есть условно высококачественные модели, для них верно, что  $A_{m} \\geqslant p_{0}$ и низкокачественные с $A_{m} \\leqslant p_{1} < p_{0}$, где $p_0$, $p_1$ фиксированы. Модели с $A_m \\in (p_1, p_0)$ неклассифицируемые и для нас не будет критичным отнести такую модель к любому из классов. \n",
    "\n",
    "Предположим, необходимо уметь классифицировать любую модель с $A_{m} \\notin ( p_{1} ,p_{2})$ с ошибкой первого рода на уровне $\\alpha < 0.5$ и ошибкой второго рода на уровне $\\beta < 0.5$. При проверке гипотезы $H_{0} :A_{m} \\geqslant p_{0}$, против альтернативы $H_{1} :A_{m} \\leqslant p_{1} < p_{0}$, наибольшую сложность для различения представляют случаи $A_{m} =p_{0}$ и $A_{m} =p_{1}$, так как в них распределения $g_{m}( \\xi _{0})$ наиболее близки. Поэтому сперва рассмотрим проверку простой гипотезы $\\hat{H}_{0} :A_{m} =p_{0}$, против простой альтернативы $\\hat{H}_{1} :A_{m} =p_{1}$. В этом случае легко построить наиболее мощный критерий, как критерий отношения правдоподобий: \n",
    "\\begin{equation}\n",
    "\\label{criteria1}\n",
    "A_{m}^{t} \\geqslant p_{0} +z_{\\alpha }\\sqrt{p_{0}( 1-p_{0}) /| O_{t}| },\n",
    "\\end{equation}\n",
    "где $z_{\\alpha }$ – квантиль уровня $\\alpha$ стандартного нормального распределения. Для данного критерия можно вычислить объем тестовой выборки $| O_{t}| $ так, чтобы ошибка второго рода равнялась $\\beta$:\n",
    "\\begin{equation}\n",
    "\\label{volume1}\n",
    "| O_{t}| =\\left(\\frac{z_{\\alpha }\\sqrt{p_{0}( 1-p_{0})} +z_{\\beta }\\sqrt{p_{1}( 1-p_{1})}}{p_{0} -p_{1}}\\right)^{2}.\n",
    "\\end{equation}\n",
    "Так как критерий наиболее мощный, то такой объем тестовой выборки необходимый и достаточный для достижения ошибок первого и второго рода $\\alpha$ и $\\beta$. Заметим, что событие из критерия для модели с $A_{m}  >p_{0}$ будет происходить вероятнее, чем для модели с  $A_{m} =p_{0}$, и наоборот, для модели с $A_{m} < p_{1}$ это же событие будет происходить менее вероятно чем для модели с $A_{m} =p_{1}$, поэтому критерий при данном объеме тестовой выборки будет подходить под ограничения на ошибки первого и второго рода при проверке сложной гипотезы  $H_{0} :A_{m} \\geqslant p_{0}$, против альтернативы $H_{1} :A_{m} \\leqslant p_{1}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sps\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def CalculatRequiredVolume(alpha, beta, p0, p1):\n",
    "    if (alpha >= 0.5) or (beta >= 0.5):\n",
    "        return -1\n",
    "    a = sps.norm(loc=0, scale=1).ppf(alpha)\n",
    "    b = sps.norm(loc=0, scale=1).ppf(beta)\n",
    "    res = p1*(1-p1)\n",
    "    res = res ** 0.5\n",
    "    res *= b\n",
    "    res += a * (p0*(1-p0)) ** 0.5\n",
    "    res /= p0 - p1\n",
    "    res *= res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чтобы различать модели с качеством <= 0.9979 и модели с качеством >= 0.9987\n",
      "с ошибками первого и второго рода на уровне 0.05 и 0.05 соответственно\n",
      "необходим размер тестовой выборки: 28294\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05  # уровень ошибки первого рода \n",
    "beta = alpha  # уровень ошибки второго рода\n",
    "p0 = 0.9987   # граница высококачественных моделей\n",
    "p1 = 0.9979   # граница низкокачественных моделей\n",
    "\n",
    "print(\"Чтобы различать модели с качеством <=\", p1, \"и модели с качеством >=\", p0) \n",
    "print(\"с ошибками первого и второго рода на уровне\", alpha, \"и\", beta, \"соответственно\")\n",
    "print(\"необходим размер тестовой выборки:\", math.ceil(CalculatRequiredVolume(alpha,beta,p0,p1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Гипотеза о преимуществе\n",
    "Допустим две модели $m_{1} ,\\ m_{2}$ показывают разную точность $A_{m1}^{t}$ и $A_{m2}^{t} ,\\ A_{m1}^{t}  >A_{m2}^{t}$, на тестовой выборке, в таком случае резонно ставить вопрос о соотношении между  $A_{m1}$ и $A_{m2}$. Рассмотрим статистику \n",
    "\\begin{equation}\n",
    "\\label{stat1}\n",
    "St\\left( A_{m1}^{t} ,A_{m2}^{t}\\right) =\\sqrt{2| O_{t}| }\\frac{A_{m1}^{t} -A_{m2}^{t}}{\\sqrt{A_{m1}^{t} +A_{m2}^{t}}\\sqrt{1-A_{m1}^{t} +1-A_{m2}^{t}}} ,\n",
    "\\end{equation}\n",
    "которая асимптотически нормальная при $| O_{t}| \\rightarrow \\infty $ и $A_{m1} =A_{m2}$. Для проверки гипотезы $H_{0} :A_{m1} \\leqslant A_{m2}$, против альтернативы $H_{1} :A_{m1}  >A_{m2}$ введем P-значение $p_{St}$:\n",
    "\\begin{equation}\n",
    "\\label{pvalue}\n",
    "p_{St}\\left( A_{m1}^{t} ,A_{m2}^{t}\\right) =1-F_{\\mathcal{N}}\\left( St\\left( A_{m1}^{t} ,A_{m2}^{t}\\right)\\right) ,\n",
    "\\end{equation}\n",
    "где $F_{\\mathcal{N}}$ -- функция стандартного нормального распределения. Тогда если отвергать гипотезу $H_{0}$ при $p_{St} \\leqslant \\alpha $ то ошибка первого рода также будет на уровне $\\alpha$. Инвертировав выражение выше относительно $A_{m2}^{t}$, можно вычислить диапазон значений $A_{m2}^{t}$ при которых $p_{St} \\leqslant \\alpha $ при фиксированном $A_{m1}^{t}$:\n",
    "\\begin{equation}\n",
    "\\label{range}\n",
    "A_{m2}^{t} \\in \\left[ 0,\\frac{2| O_{t}| A_{m1}^{t} -z_{\\alpha }^{2} A_{m1}^{t} +z_{\\alpha }^{2} -\\sqrt{D}}{2| O_{t}| +z_{\\alpha }^{2}}\\right] ,\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "D=\\left( 2| O_{t}| A_{m1}^{t} -z_{\\alpha }^{2} A_{m1}^{t} +z_{\\alpha }^{2}\\right)^{2} -A_{m1}^{t}\\left( 2| O_{t}| +z_{\\alpha }^{2}\\right)\\left( 2| O_{t}| A_{m1}^{t} -2z_{\\alpha }^{2} +z_{\\alpha }^{2} A_{m1}^{t}\\right) .\n",
    "\\end{equation}\n",
    "Другими словами, если $A_{m2}^{t}$ принадлежит данному диапазону, то можно говорить, что преимущество в точности модели $m1$ над моделью $m2$ статистически значимо, на уровне ошибки первого рода $\\alpha$.\n",
    "\n",
    "Также, можно вычислить необходимый размер тестовой выборки $| O_{t}| $, при котором значения Accuracy  $A_{m1}^{t}$ и $A_{m2}^{t} ,\\ A_{m1}^{t}  >A_{m2}^{t}$, говорят о статистически значимом преимуществе модели $m1$ над моделью $m2$: \n",
    "\\begin{equation}\n",
    "\\label{volume2}\n",
    "| O_{t}| \\geqslant z_{\\alpha }^{2}\\frac{\\left( A_{m1}^{t} +A_{m2}^{t}\\right)\\left( 1-A_{m1}^{t} +1-A_{m2}^{t}\\right)}{2\\left( A_{m1}^{t} -A_{m2}^{t}\\right)^{2}} .\n",
    "\\end{equation}\n",
    "Эта формула дает представление о том, каким должен быть размер тестовой выборки, чтобы по полученным $A_{m1}^{t}$ и $A_{m2}^{t} ,\\ A_{m1}^{t}  >A_{m2}^{t}$ можно было бы заявлять о преимуществе модели $m1$ над моделью $m2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sps\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def BorderDistinctness(alpha, A, n):\n",
    "    z = sps.norm(loc=0, scale=1).ppf(alpha)\n",
    "    D = 2*n*A -z*z*A + z*z\n",
    "    D *= D\n",
    "    D -= (2*n + z*z) * (2*n*A*A - 2*z*z*A + z*z*A*A)\n",
    "    res = 2*n*A - z*z*A + z*z - D**(0.5)\n",
    "    res /= 2*n +z*z\n",
    "    return res\n",
    "\n",
    "def RequiredSizeDistinguishability(alpha, A1, A2):\n",
    "    if A1 <= A2:\n",
    "        return -1\n",
    "    z = sps.norm(loc=0, scale=1).ppf(alpha)\n",
    "    res = A1 + A2\n",
    "    res *= 2 - A1 - A2\n",
    "    res /= 2 * (A1 - A2) ** 2\n",
    "    res *= z * z\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель с Accuracy 0.9395 на тестовой выборке с объемом 10000\n",
      "имеет статистически значимое преимущество с уровнем ошибки первого рода 0.05\n",
      "над моделями с Accuracy <= 0.9338343554205788\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05  # уровень ошибки первого рода \n",
    "A1 = 0.9395   # Accuracy рассматриваемой модели\n",
    "n = 10000     # объем тестовой выборки датасета\n",
    "\n",
    "print(\"Модель с Accuracy\", A1, \"на тестовой выборке с объемом\", n) \n",
    "print(\"имеет статистически значимое преимущество с уровнем ошибки первого рода\", alpha)\n",
    "print(\"над моделями с Accuracy <=\", BorderDistinctness(alpha1, A1, n1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чтобы модель с Accuracy 0.9987 имела статистически значимое\n",
      "преимущество над моделью с Accuracy 0.9984\n",
      "с уровнем ошибки первого рода 0.05\n",
      "необходимо, чтобы объем тестовой выборки был >= 87053\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05  # уровень ошибки первого рода\n",
    "A1 = 0.9987   # Accuracy более точной из двух моделей\n",
    "A2 = 0.9984   # Accuracy менее точной из двух моделей\n",
    "\n",
    "print(\"Чтобы модель с Accuracy\", A1, \"имела статистически значимое\")\n",
    "print(\"преимущество над моделью с Accuracy\", A2) \n",
    "print(\"с уровнем ошибки первого рода\", alpha)\n",
    "print(\"необходимо, чтобы объем тестовой выборки был >=\", math.ceil(RequiredSizeDistinguishability(alpha1, A1, A2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
